llm {
  # LLM Configuration
  provider = "OLLAMA"  # Options: OLLAMA, OPENAI, ANTHROPIC
  baseUrl = "http://172.31.6.131:11434"
  model = "gpt-oss:120b"
  apiKey = ""  # Required for OPENAI and ANTHROPIC, optional for OLLAMA
}

mcp {
  # MCP Server Configuration
  serverUrl = "http://localhost:8081"
}